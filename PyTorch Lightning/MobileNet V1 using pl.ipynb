{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Implement MobileNet V1 using PyTorch Lightning Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError:  # Install PyTorch Lightning if not installed\n",
    "    !pip install pytorch-lightning\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Other\n",
    "from pathlib import Path\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "File Structure:\n",
    "```\n",
    "root\n",
    "├── Data\n",
    "└── Checkpoint\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Hyper-parameters\n",
    "INPUT_SIZE = 784  # 28x28\n",
    "HIDDEN_SIZE = 500\n",
    "NUM_CLASSES = 102\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Directory\n",
    "ROOT_DIR = Path(\"/root/jupyter_projects\")  # Your working directory.\n",
    "DATA_DIR = ROOT_DIR / \"Data\"  # Directory where the data are/should be downloaded.\n",
    "CHECKPOINT_DIR = ROOT_DIR / \"Checkpoint\"  # Directory where the pretrained models are saved.\n",
    "DATASET_DIR = DATA_DIR / \"oxford-102-flowers\"  # Directory of the dataset.\n",
    "\n",
    "# Path\n",
    "TRAIN_LABEL_PATH = DATASET_DIR / \"train.txt\"\n",
    "VAL_LABEL_PATH = DATASET_DIR / \"valid.txt\"\n",
    "TEST_LABEL_PATH = DATASET_DIR / \"test.txt\"\n",
    "\n",
    "# Dataset\n",
    "URL = \"https://www.dropbox.com/s/hqiryv0g62lp878/oxford-102-flowers.tgz?raw=1\"\n",
    "FILE_NAME = \"Flowers102.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "    def __init__(self, url, file_name, data_dir):\n",
    "        self.url = url  # Dataset download link.\n",
    "        self.file_name = file_name  # The name of the downloaded file.\n",
    "        self.data_dir = data_dir\n",
    "        self.file_path = data_dir / file_name  # Path to download file.\n",
    "\n",
    "    def download_dataset(self):\n",
    "        try:\n",
    "            r = requests.get(self.url, allow_redirects=True)\n",
    "            open(self.file_path, 'wb').write(r.content)\n",
    "            print('[Success] Dataset downloaded successfully')\n",
    "        except:\n",
    "            print('[Error] Dataset downloaded failed')\n",
    "            raise\n",
    "\n",
    "    def unzip_dataset(self):\n",
    "        zip_file_path = self.file_path\n",
    "        extract_directory = self.data_dir\n",
    "        try:\n",
    "            with tarfile.open(zip_file_path, \"r\") as tar_ref:\n",
    "                tar_ref.extractall(extract_directory)\n",
    "            print('[Success] Dataset extracted successfully')\n",
    "            Path.unlink(self.file_path)  # Remove zip file.\n",
    "        except:\n",
    "            print('[Error] Dataset extracted failed')\n",
    "            raise\n",
    "\n",
    "    def create_dataset(self):\n",
    "        if not DATASET_DIR.is_dir():  # Dataset is not downloaded yet.\n",
    "            self.download_dataset()\n",
    "            self.unzip_dataset()\n",
    "        else:\n",
    "            print('[Alert] Dataset already exist')\n",
    "\n",
    "    def dataset_label(self, label_path):\n",
    "        \"\"\"\n",
    "        This function reads the label file and generates the path and class of the data in the dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        label_path : str\n",
    "            path of the label file(train label, val label, test label)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        path_list : list\n",
    "            path of all the data in the dataset\n",
    "        class_list : list\n",
    "            class of all the data in the dataset\n",
    "        \"\"\"\n",
    "        path_list = []  # Store the path of images.\n",
    "        class_list = []  # Store the class names.\n",
    "        with open(label_path) as file:  # Get the content of the label file.\n",
    "            lines = file.readlines()\n",
    "        for line in lines:\n",
    "            data_path, data_class = line.strip().split(' ')\n",
    "            data_path = str(self.data_dir / data_path)  # Convert to string type.\n",
    "            path_list.append(data_path)  # Store the path of images in list.\n",
    "            class_list.append(int(data_class))\n",
    "        return path_list, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CreateDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Flowers102 \u001b[38;5;241m=\u001b[39m \u001b[43mCreateDataset\u001b[49m(URL, FILE_NAME, DATA_DIR)\n\u001b[1;32m      2\u001b[0m train_path_list, train_class_list \u001b[38;5;241m=\u001b[39m Flowers102\u001b[38;5;241m.\u001b[39mdataset_label(TRAIN_LABEL_PATH)\n\u001b[1;32m      3\u001b[0m val_path_list, val_class_list \u001b[38;5;241m=\u001b[39m Flowers102\u001b[38;5;241m.\u001b[39mdataset_label(VAL_LABEL_PATH)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CreateDataset' is not defined"
     ]
    }
   ],
   "source": [
    "Flowers102 = CreateDataset(URL, FILE_NAME, DATA_DIR)\n",
    "\n",
    "train_path_list, train_class_list = Flowers102.dataset_label(TRAIN_LABEL_PATH)\n",
    "val_path_list, val_class_list = Flowers102.dataset_label(VAL_LABEL_PATH)\n",
    "test_path_list, test_class_list = Flowers102.dataset_label(TEST_LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Flowers102Dataset(data.Dataset):\n",
    "    def __init__(self, data_path, data_class, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.data_class = data_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.data_path[idx]\n",
    "        # For numpy array:\n",
    "        # image = cv2.imread(image_filepath)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # For torch tensor:\n",
    "        image = torchvision.io.read_image(image_filepath)  # uint8 type\n",
    "        image = image.to(torch.float)\n",
    "\n",
    "        label = self.data_class[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MobileNetV1(pl.LightningModule):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        def conv_bn(ch_in, ch_out, stride):  # convolution batch normalization\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(ch_in, ch_out, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(ch_out),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        def conv_dw(ch_in, ch_out, stride):  # depth-wise separable convolution\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(ch_in, ch_in, 3, stride, 1, groups=ch_in, bias=False),\n",
    "                nn.BatchNorm2d(ch_in),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(ch_in, ch_out, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ch_out),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            conv_bn(in_channels, 32, 2),\n",
    "            conv_dw(32, 64, 1),\n",
    "            conv_dw(64, 128, 2),\n",
    "            conv_dw(128, 128, 1),\n",
    "            conv_dw(128, 256, 2),\n",
    "            conv_dw(256, 256, 1),\n",
    "            conv_dw(256, 512, 2),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 1024, 2),\n",
    "            conv_dw(1024, 1024, 1),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "\n",
    "        self.img_transforms = transforms.Compose([\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMobileNet_v1\u001b[39;00m(\u001b[43mpl\u001b[49m\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "class MobileNetV1(pl.LightningModule):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self.model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        # use key 'log'\n",
    "        return {\"loss\": loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = Flowers102Dataset(\n",
    "            data_path=train_path_list,\n",
    "            data_class=train_class_list,\n",
    "            transform=self.img_transforms\n",
    "        )\n",
    "        train_loader = data.DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = Flowers102Dataset(\n",
    "            data_path=val_path_list,\n",
    "            data_class=val_class_list,\n",
    "            transform=self.img_transforms\n",
    "        )\n",
    "        val_loader = data.DataLoader(\n",
    "            dataset=val_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        return val_loader\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self.model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        # use key 'log'\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = MobileNetV1(in_channels=3, num_classes=NUM_CLASSES)\n",
    "    trainer = Trainer(max_epochs=NUM_EPOCHS)\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
